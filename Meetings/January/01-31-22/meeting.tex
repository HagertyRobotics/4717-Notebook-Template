%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                insertmeeting
% 1) Title (something creative & funny?)
% 2) Date (MM/DD/YYYY)
% 3) Location (ex. Hagerty High School)
% 4) People/Committees Present 
% 5) Picture 
% 6) Start Time & Stop Time (ex. 12:30AM to 4:30PM)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\insertmeeting 
	{Webcam Wonders} 
	{01/31/22} 
	{Hagerty High School}
	{Anouska, James, Ritam, Samantha}
	{Images/RobotPics/robot.jpg}
	{2:30 - 4:30}
	
\hhscommittee{Software}
\noindent\hfil\rule{\textwidth}{.4pt}\hfil
\subsubsection*{Goals}
\begin{itemize}
    \item Test vision with new team elements  

\end{itemize} 

\noindent\hfil\rule{\textwidth}{.4pt}\hfil

\subsubsection*{Accomplishments}
After the new team elements were 3D printed, we decided to test the HSV vision using FTC Dashboard. After some time researching why dashboard would not show the camera, we decided to test sample code from First Tech Challenge Robot Controller to see if the camera work. We then found in the documentation for FTC Dashboard that we did not have a line of code that starts the camera. Once we included it, the sample code worked. We put the same line of code in our code and got dashboard's camera to work. Since the values for the hue, saturation, and value were hard coded, we decided to use a range for each value. We added configurations for the maximum and minimum numbers of hue, saturation, and value. After adding the configurations, we made the camera show the output after the image is eroded. This allowed us to see how the different values affected how the element was seen. In different lightings, the values would need to change, so this is where the range comes in handy. 
 

\whatsnext{
\begin{itemize}
    \item Continue testing and work on autonomous
\end{itemize} 
}

